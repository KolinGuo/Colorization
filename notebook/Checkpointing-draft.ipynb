{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dirty-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Colorization/src\")  # Append path to src\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "minute-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.dataset import load_dataset\n",
    "from networks.models import get_model\n",
    "from networks.losses import get_loss_func\n",
    "from networks.metrics import AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "danish-active",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-xf6b2st5 because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=10.16s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "root = '/Colorization/data/train2017'\n",
    "annFile = '/Colorization/data/annotations/instances_train2017.json'\n",
    "batch_size = 32\n",
    "train_dataset = load_dataset(root, annFile, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "informative-table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.29s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "val_root = '/Colorization/data/val2017'\n",
    "val_annFile = '/Colorization/data/annotations/instances_val2017.json'\n",
    "val_dataset = load_dataset(val_root, val_annFile, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welsh-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "pytorch_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "painted-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = 'eccv16_pretrained'\n",
    "model = get_model(model_str).to(pytorch_device)\n",
    "\n",
    "loss_func_str = 'MSELoss'\n",
    "loss_func = get_loss_func(loss_func_str, None)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=3*1e-5,\n",
    "                             betas=(0.9,0.99),\n",
    "                             weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "growing-girlfriend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('eccv16_pretrained', 3697, 157)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name, len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "latin-enforcement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(16218842., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1 tensor(15751429., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2 tensor(17927312., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3 tensor(16074726., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "4 tensor(13535334., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "5 tensor(16559589., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "6 tensor(17736148., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "7 tensor(15183708., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "8 tensor(19484728., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "9 tensor(15551604., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "10 tensor(13447608., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "11 tensor(20923080., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "12 tensor(15453912., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "13 tensor(15345683., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "14 tensor(15757264., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "15 tensor(13979877., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "16 tensor(18236940., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "17 tensor(17400880., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "18 tensor(16073621., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "19 tensor(15946712., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "20 tensor(17342348., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "21 tensor(13923974., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "22 tensor(17284268., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "23 tensor(15893924., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "24 tensor(19705984., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "25 tensor(16642953., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "26 tensor(17303738., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "27 tensor(13867344., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "28 tensor(14766518., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "29 tensor(16497888., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "30 tensor(15486598., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "31 tensor(17510796., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "32 tensor(15465745., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "33 tensor(18757572., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "34 tensor(14260487., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "35 tensor(15065564., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "36 tensor(15558685., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "37 tensor(17640138., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "38 tensor(16359580., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "39 tensor(14618582., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "40 tensor(17375256., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "41 tensor(15540424., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "42 tensor(14337654., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "43 tensor(16709202., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "44 tensor(14129333., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "45 tensor(18518776., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "46 tensor(17057234., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "47 tensor(15593722., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "48 tensor(19671772., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "49 tensor(17789774., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "50 tensor(15245315., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "51 tensor(16171893., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "52 tensor(15234552., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "53 tensor(15948015., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "54 tensor(17430970., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "55 tensor(17082832., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "56 tensor(15158004., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "57 tensor(13279172., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "58 tensor(16302160., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "59 tensor(14982996., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "60 tensor(15313552., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "61 tensor(13081398., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "62 tensor(17361168., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "63 tensor(13659732., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "64 tensor(13855100., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "65 tensor(16449570., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "66 tensor(15312506., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "67 tensor(16203757., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "68 tensor(16751979., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "69 tensor(16323022., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "70 tensor(16553916., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "71 tensor(14276436., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "72 tensor(13401524., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "73 tensor(17419816., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "74 tensor(16797164., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "75 tensor(15088583., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "76 tensor(16019873., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "77 tensor(18787140., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "78 tensor(13449592., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "79 tensor(16752558., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "80 tensor(15179032., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "81 tensor(17013474., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "82 tensor(14608560., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "83 tensor(15070965., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "84 tensor(14338088., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "85 tensor(14961066., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "86 tensor(13951632., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "87 tensor(18627060., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "88 tensor(16959162., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "89 tensor(15484931., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "90 tensor(16177180., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "91 tensor(16335944., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "92 tensor(14980896., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "93 tensor(15580133., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "94 tensor(13215104., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "95 tensor(16194633., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "96 tensor(15534408., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "97 tensor(16872272., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "98 tensor(16164368., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "99 tensor(16822808., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "100 tensor(18186148., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "101 tensor(14247678., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "102 tensor(15539943., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "103 tensor(14060658., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "104 tensor(16451744., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "105 tensor(15518582., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "106 tensor(15861374., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "107 tensor(17482864., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "108 tensor(14755691., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "109 tensor(16100706., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "110 tensor(18961908., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "111 tensor(15878155., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "112 tensor(15304970., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "113 tensor(19858708., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "114 tensor(19931424., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "115 tensor(19382856., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "116 tensor(17378874., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "117 tensor(15529054., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "118 tensor(12780476., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "119 tensor(16889268., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "120 tensor(17171602., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "121 tensor(16456160., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "122 tensor(15755590., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "123 tensor(14411852., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "124 tensor(14503113., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "125 tensor(16147663., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "126 tensor(14124466., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "127 tensor(14740726., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "128 tensor(19168324., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "129 tensor(13839328., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "130 tensor(15256380., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "131 tensor(15889445., device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 tensor(17598548., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "133 tensor(17305192., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "134 tensor(14096515., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "135 tensor(16980280., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "136 tensor(13154812., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "137 tensor(11580624., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "138 tensor(15188478., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "139 tensor(12395349., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "140 tensor(18885714., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "141 tensor(18441768., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "142 tensor(15961508., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "143 tensor(18568416., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "144 tensor(13338731., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "145 tensor(15082103., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "146 tensor(14616120., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "147 tensor(16775224., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "148 tensor(17621196., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "149 tensor(16892604., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "150 tensor(16801656., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "151 tensor(17818308., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "152 tensor(16313604., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "153 tensor(17214244., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "154 tensor(17379520., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "155 tensor(16105495., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "156 tensor(14760116., device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.8754, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## Eval metric\n",
    "auc_metric = AUC(step_size = 1.0,\n",
    "                 device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "for i, (img_l, y) in enumerate(val_dataset):\n",
    "    img_l = img_l.to(pytorch_device)\n",
    "    y = y.to(pytorch_device)\n",
    "    y_pred = model(img_l)\n",
    "#     print(y_pred.shape, y.shape)\n",
    "    loss = loss_func(y_pred, y)\n",
    "    #loss = loss_func(model.normalize_ab(y_pred), model.normalize_ab(y))\n",
    "    print(i, loss)\n",
    "    \n",
    "#     print(np.max(y_pred.cpu().detach().numpy()), np.min(y_pred.cpu().detach().numpy()))\n",
    "#     diff = y_pred.cpu() - y.cpu()\n",
    "#     print(diff.detach().numpy().shape)\n",
    "#     diff = np.linalg.norm(diff.detach().numpy(), axis=1)\n",
    "#     print(diff.shape)\n",
    "#     diff_torch = torch.norm(y_pred-y, dim=1)\n",
    "#     print(diff_torch.shape)\n",
    "#     np.testing.assert_allclose(diff_torch.cpu().detach().numpy(), diff)\n",
    "#     print(np.max(diff), np.min(diff))\n",
    "#     print('cnt: ', np.count_nonzero(diff <= 150))\n",
    "#     loss = np.sum(diff) / 2 / img_l.shape[0]\n",
    "#     print(loss)\n",
    "    \n",
    "#     diff = y.cpu() - y.cpu()\n",
    "#     print(diff.detach().numpy().shape)\n",
    "#     diff = np.linalg.norm(diff.detach().numpy(), axis=1) ** 2\n",
    "#     print(diff.shape)\n",
    "#     print(np.max(diff), np.min(diff))\n",
    "#     print('cnt: ', np.count_nonzero(diff <= 0)/ np.prod(diff.shape))\n",
    "#     loss = np.sum(diff) / 2 / img_l.shape[0]\n",
    "#     print(loss)\n",
    "    \n",
    "    auc_metric.reset()\n",
    "    auc_metric.update((y_pred, y))\n",
    "    \n",
    "#     roc_auc_metric.reset()\n",
    "#     roc_auc_metric.update((y_pred.reshape(-1), y.reshape(-1)))\n",
    "#     print(roc_auc_metric.compute())\n",
    "\n",
    "print(auc_metric.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-cooperation",
   "metadata": {},
   "source": [
    "### Outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "terminal-warning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([151])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'diff_torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f5aa3c9ae036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'diff_torch' is not defined"
     ]
    }
   ],
   "source": [
    "step = 1.0\n",
    "thresholds = torch.arange(0, 150+step, step=step).to(pytorch_device)\n",
    "print(type(thresholds))\n",
    "print(thresholds.shape)\n",
    "print(thresholds[None,None,None,...].shape, diff_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-camping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sensitive-vinyl",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([151])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(thresholds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "regulated-breed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.numel(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC_metric(y_pred: torch.Tensor, y: torch.Tensor) -> float:\n",
    "    step = 1\n",
    "    thresholds = torch.arange(0, 150+step, step=step).to(pytorch_device)\n",
    "    dist = torch.norm(y_pred-y, dim=1)\n",
    "    pos_cnt = torch.sum(torch.le(dist[...,None], thresholds[None,None,None,...]), dim=(0,1,2))\n",
    "    tot_cnt += torch.numel(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "auburn-possible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([     0,    466,   1834,   3982,   7190,  11262,  16062,  21437,  27440,\n",
      "         33744,  40254,  47248,  54968,  62934,  71296,  79735,  88089,  96167,\n",
      "        104364, 112671, 120886, 129022, 137113, 144687, 151826, 158527, 164690,\n",
      "        170659, 176628, 182180, 187559, 192688, 197459, 201887, 206149, 210065,\n",
      "        213915, 217441, 220753, 223982, 227035, 229954, 232607, 235138, 237417,\n",
      "        239509, 241403, 243226, 244882, 246366, 247733, 248956, 249974, 250968,\n",
      "        251866, 252824, 253664, 254472, 255214, 255913, 256558, 257130, 257654,\n",
      "        258134, 258536, 258935, 259317, 259607, 259860, 260079, 260280, 260475,\n",
      "        260645, 260810, 260948, 261070, 261195, 261323, 261437, 261531, 261607,\n",
      "        261682, 261744, 261802, 261864, 261905, 261953, 261981, 262009, 262039,\n",
      "        262064, 262084, 262099, 262115, 262122, 262129, 262136, 262140, 262141,\n",
      "        262143, 262144, 262144, 262144, 262144, 262144, 262144, 262144, 262144,\n",
      "        262144, 262144, 262144, 262144, 262144, 262144, 262144, 262144, 262144,\n",
      "        262144, 262144, 262144, 262144, 262144, 262144, 262144, 262144, 262144,\n",
      "        262144, 262144, 262144, 262144, 262144, 262144, 262144, 262144, 262144,\n",
      "        262144, 262144, 262144, 262144, 262144, 262144, 262144, 262144, 262144,\n",
      "        262144, 262144, 262144, 262144, 262144, 262144, 262144],\n",
      "       device='cuda:0') 262144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8386, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = diff_torch\n",
    "pos_cnt = torch.sum(torch.le(dist[...,None], thresholds[None,None,None,...]), dim=(0,1,2))\n",
    "tot_cnt = torch.numel(dist)\n",
    "print(pos_cnt, tot_cnt)\n",
    "torch.sum(pos_cnt / tot_cnt) / torch.numel(pos_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "designing-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.dataset import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reasonable-turtle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-lz4yu38j because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=10.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "root = '/Colorization/data/train2017'\n",
    "annFile = '/Colorization/data/annotations/instances_train2017.json'\n",
    "batch_size = 64\n",
    "train_dataset = load_dataset(root, annFile, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hazardous-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "pytorch_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "otherwise-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.eccv16 import eccv16\n",
    "\n",
    "model = eccv16(pretrained=True).to(pytorch_device)\n",
    "    \n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3*1e-5,betas=(0.9,0.99),weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hungry-negative",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3455: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48900.44\n",
      "0 2391416832.0 Time: 2.087425708770752 sec\n",
      "45685.168\n",
      "1 2087234432.0 Time: 8.31327772140503 sec\n",
      "50968.28\n",
      "2 2597967104.0 Time: 6.674348592758179 sec\n",
      "42881.805\n",
      "3 1838942208.0 Time: 6.67439341545105 sec\n",
      "45425.117\n",
      "4 2063548032.0 Time: 6.694308042526245 sec\n",
      "40564.984\n",
      "5 1645593216.0 Time: 6.673346757888794 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-47112883c3f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimg_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytorch_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytorch_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/torchvision/datasets/coco.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~Colorization/src/networks/dataset.py\u001b[0m in \u001b[0;36minput_transforms\u001b[0;34m(img_rgb_orig, target, HW, resample)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg_rgb_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rgb_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mimg_lab_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rgb_rs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mimg_l_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_lab_rs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2lab\u001b[0;34m(rgb, illuminant, observer)\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mwiki\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mStandard_illuminant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \"\"\"\n\u001b[0;32m-> 1092\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxyz2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb2xyz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0milluminant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2xyz\u001b[0;34m(rgb)\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_colorarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.04045\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.055\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1.055\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m12.92\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mxyz_from_rgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "for i, (img_l, y) in enumerate(train_dataset):\n",
    "    img_l = img_l.to(pytorch_device)\n",
    "    y = y.to(pytorch_device)\n",
    "    y_pred = model(img_l)\n",
    "    print(np.linalg.norm(y_pred.detach().cpu().numpy() - y.cpu().numpy()))\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    #loss = criterion(model.normalize_ab(y_pred), model.normalize_ab(y))\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(i, loss.item(), f'Time: {toc-tic} sec')\n",
    "    tic = time.time()\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-butterfly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
