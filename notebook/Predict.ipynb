{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "celtic-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Colorization/src\")  # Append path to src\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "public-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import get_parser, predict\n",
    "run_cmd = './src/predict.py eccv16_pretrained'  # Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "supported-cradle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num GPUs Available: 1\n",
      "\n",
      "Predict Dataset \"val2017\" loaded: 5000 samples, 5000 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSaving predicted mask to \"/Colorization/data/outputs/eccv16_pretrained\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3455: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "  0%|          | 22/5000 [00:06<25:07,  3.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-21f26209efc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                        lineno=1128, append=False)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~Colorization/src/predict.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the module in evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_orig_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_rs_l\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Passing data to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~Colorization/src/networks/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mimg_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_image_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mimg_rs_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_image_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rs_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m#img = Image.open(img_path).convert('RGB')     # PIL.Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~Colorization/src/networks/dataset.py\u001b[0m in \u001b[0;36mpredict_acc_img_transform\u001b[0;34m(img_path, img_rgb_orig, img_rgb_rs)\u001b[0m\n\u001b[1;32m     51\u001b[0m                               img_rgb_rs: np.ndarray) -> Tuple[torch.Tensor]:\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# return original size L and resized L as torch Tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mimg_lab_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rgb_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mimg_lab_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rgb_rs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2lab\u001b[0;34m(rgb, illuminant, observer)\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mwiki\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mStandard_illuminant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \"\"\"\n\u001b[0;32m-> 1092\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxyz2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb2xyz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0milluminant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mxyz2lab\u001b[0;34m(xyz, illuminant, observer)\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0;31m# Nonlinear distortion and linear transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.008856\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7.787\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m16.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m116.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parser = get_parser()\n",
    "predict_args = parser.parse_args(run_cmd.split()[1:])\n",
    "\n",
    "# Ignore skimage.color.colorconv.lab2xyz() out-of-range warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message='Color data out of range.+',\n",
    "                       category=UserWarning, \n",
    "                       module='skimage.color.colorconv',\n",
    "                       lineno=1128, append=False)\n",
    "\n",
    "predict(predict_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-glass",
   "metadata": {},
   "source": [
    "## Detailed function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "furnished-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Colorization/src\")  # Append path to src\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from predict import get_parser, predict\n",
    "run_cmd = './src/predict.py eccv16_pretrained'  # Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broke-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser()\n",
    "args = parser.parse_args(run_cmd.split()[1:])\n",
    "\n",
    "# Ignore skimage.color.colorconv.lab2xyz() out-of-range warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message='Color data out of range.+',\n",
    "                       category=UserWarning, \n",
    "                       module='skimage.color.colorconv',\n",
    "                       lineno=1128, append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "isolated-knowing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Colorization/data/val2017'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "formal-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from networks.dataset import load_predict_dataset, CocoColorization, predict_acc_img_transform\n",
    "from networks.models import get_model\n",
    "from util import postprocess_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cognitive-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4, <torch.utils.data.dataset.Subset at 0x7f4b772b7080>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CocoColorization(args.data_dir, predict_acc_img_transform)\n",
    "subdataset = torch.utils.data.Subset(dataset, [1,3, 4, 5])\n",
    "len(dataset), len(subdataset), subdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "honey-annotation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (('/Colorization/data/val2017/000000000285.jpg',), tensor([[[[51.8235, 44.0512, 40.0087,  ..., 72.2689, 72.5584, 71.1523],\n",
      "          [59.5481, 62.3011, 45.6373,  ..., 77.9122, 75.1700, 75.2707],\n",
      "          [38.8283, 62.8991, 70.4567,  ..., 67.9916, 69.0071, 76.9883],\n",
      "          ...,\n",
      "          [23.3172, 32.5907, 35.6902,  ..., 12.9623,  5.2489,  7.3205],\n",
      "          [30.7159, 35.7802, 35.9490,  ..., 12.7607,  7.7941,  7.3397],\n",
      "          [33.9476, 33.2658, 38.6541,  ..., 12.6016,  9.6292,  6.8093]]]]), tensor([[[[52.0879, 47.2241, 51.6007,  ..., 56.9871, 68.9948, 72.8828],\n",
      "          [43.9195, 57.1403, 51.1749,  ..., 56.5617, 59.6642, 61.3878],\n",
      "          [38.1374, 47.4100, 57.2868,  ..., 54.9778, 65.0723, 64.1271],\n",
      "          ...,\n",
      "          [35.9042, 48.8552, 57.4748,  ..., 11.7438,  8.8843, 12.1989],\n",
      "          [30.3810, 46.5353, 53.1783,  ..., 12.2148,  9.9904,  9.0581],\n",
      "          [32.9801, 40.3633, 53.0939,  ..., 10.1786, 12.3160,  8.1667]]]]))\n",
      "1 (('/Colorization/data/val2017/000000000724.jpg',), tensor([[[[22.1445, 15.5569, 18.4662,  ..., 65.9320, 63.5435, 65.7800],\n",
      "          [13.7386,  8.2108, 10.3142,  ..., 63.1694, 61.3762, 63.4211],\n",
      "          [13.5735,  9.2176, 11.7917,  ..., 64.5399, 63.4211, 64.9121],\n",
      "          ...,\n",
      "          [75.9908, 63.3387, 61.7425,  ..., 13.0323, 11.8059, 19.4447],\n",
      "          [66.5670, 61.0495, 71.1828,  ...,  9.0629,  7.7908, 14.7252],\n",
      "          [76.5852, 60.6672, 64.7253,  ..., 16.6591, 15.6085, 22.5865]]]]), tensor([[[[16.1246, 13.8608, 15.2789,  ..., 63.5989, 63.9172, 64.2354],\n",
      "          [11.9735, 10.5258, 13.9265,  ..., 63.6111, 63.5158, 63.9300],\n",
      "          [12.8483, 11.8650, 14.8409,  ..., 64.6212, 63.5569, 63.9300],\n",
      "          ...,\n",
      "          [72.5339, 72.7958, 75.8925,  ..., 13.1702, 15.7751, 22.0316],\n",
      "          [70.7878, 66.9521, 69.1263,  ..., 13.1384, 12.3997, 17.8188],\n",
      "          [69.1596, 64.2051, 59.4685,  ..., 13.8422, 12.8889, 17.0689]]]]))\n",
      "2 (('/Colorization/data/val2017/000000000776.jpg',), tensor([[[[44.4181, 43.9260, 44.3797,  ...,  8.2998,  7.4594,  4.9877],\n",
      "          [50.1955, 51.5471, 51.6994,  ...,  5.4404,  5.6475,  6.6798],\n",
      "          [50.0544, 52.6029, 52.8119,  ...,  5.1224,  5.1053,  4.9877],\n",
      "          ...,\n",
      "          [33.5129, 37.3949, 70.3540,  ..., 61.5463, 62.2111, 62.2111],\n",
      "          [39.8803, 17.9773,  3.3891,  ..., 61.7298, 62.0996, 61.6581],\n",
      "          [42.6013, 33.0330, 12.7140,  ..., 60.7037, 61.0734, 60.4420]]]]), tensor([[[[48.2037, 48.7565, 48.6493,  ...,  8.0424,  6.2931,  5.7607],\n",
      "          [54.1559, 54.4320, 51.2613,  ..., 11.3468,  9.4484,  5.4404],\n",
      "          [55.0383, 53.2540, 53.7048,  ..., 13.3590, 17.7160, 13.0149],\n",
      "          ...,\n",
      "          [43.0413, 41.0975, 30.8826,  ..., 62.2526, 62.3634, 62.7316],\n",
      "          [35.8158, 51.0723, 35.9180,  ..., 61.0708, 61.4373, 62.4699],\n",
      "          [35.7927, 29.1262, 45.5310,  ..., 60.0650, 60.9536, 61.3238]]]]))\n",
      "3 (('/Colorization/data/val2017/000000000785.jpg',), tensor([[[[82.7232, 82.7232, 82.7232,  ..., 87.4576, 87.4576, 87.4576],\n",
      "          [82.7232, 83.0821, 83.0821,  ..., 87.1024, 87.1024, 87.1024],\n",
      "          [83.4407, 83.4407, 83.4407,  ..., 87.4576, 87.4576, 87.4576],\n",
      "          ...,\n",
      "          [90.2876, 88.1669, 84.9653,  ..., 79.7853, 80.5083, 80.8693],\n",
      "          [87.8124, 87.4576, 87.2564,  ..., 78.0265, 78.0265, 78.3352],\n",
      "          [86.5720, 85.1201, 87.7893,  ..., 76.9705, 77.6988, 78.1571]]]]), tensor([[[[82.7232, 82.7232, 82.7503,  ..., 86.9011, 86.9011, 87.4576],\n",
      "          [83.4407, 83.0821, 82.7232,  ..., 87.4576, 87.4576, 87.4576],\n",
      "          [83.0821, 83.0821, 83.0821,  ..., 87.4576, 87.4576, 87.4576],\n",
      "          ...,\n",
      "          [87.7632, 87.0793, 85.2991,  ..., 79.3000, 79.8397, 79.0881],\n",
      "          [88.1669, 85.4011, 83.8692,  ..., 77.9785, 79.0881, 80.1740],\n",
      "          [86.7992, 85.5806, 84.4345,  ..., 77.1221, 77.6148, 77.9508]]]]))\n"
     ]
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(subdataset, batch_size=1, shuffle=False)\n",
    "for i, (a, b, c) in enumerate(data_loader):\n",
    "    print(i, (a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "charming-examination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('/Colorization/data/val2017/000000000285.jpg',\n",
       "  tensor([[[51.8235, 44.0512, 40.0087,  ..., 72.2689, 72.5584, 71.1523],\n",
       "           [59.5481, 62.3011, 45.6373,  ..., 77.9122, 75.1700, 75.2707],\n",
       "           [38.8283, 62.8991, 70.4567,  ..., 67.9916, 69.0071, 76.9883],\n",
       "           ...,\n",
       "           [23.3172, 32.5907, 35.6902,  ..., 12.9623,  5.2489,  7.3205],\n",
       "           [30.7159, 35.7802, 35.9490,  ..., 12.7607,  7.7941,  7.3397],\n",
       "           [33.9476, 33.2658, 38.6541,  ..., 12.6016,  9.6292,  6.8093]]]),\n",
       "  tensor([[[52.0879, 47.2241, 51.6007,  ..., 56.9871, 68.9948, 72.8828],\n",
       "           [43.9195, 57.1403, 51.1749,  ..., 56.5617, 59.6642, 61.3878],\n",
       "           [38.1374, 47.4100, 57.2868,  ..., 54.9778, 65.0723, 64.1271],\n",
       "           ...,\n",
       "           [35.9042, 48.8552, 57.4748,  ..., 11.7438,  8.8843, 12.1989],\n",
       "           [30.3810, 46.5353, 53.1783,  ..., 12.2148,  9.9904,  9.0581],\n",
       "           [32.9801, 40.3633, 53.0939,  ..., 10.1786, 12.3160,  8.1667]]])),\n",
       " ('/Colorization/data/val2017/000000000285.jpg',\n",
       "  tensor([[[51.8235, 44.0512, 40.0087,  ..., 72.2689, 72.5584, 71.1523],\n",
       "           [59.5481, 62.3011, 45.6373,  ..., 77.9122, 75.1700, 75.2707],\n",
       "           [38.8283, 62.8991, 70.4567,  ..., 67.9916, 69.0071, 76.9883],\n",
       "           ...,\n",
       "           [23.3172, 32.5907, 35.6902,  ..., 12.9623,  5.2489,  7.3205],\n",
       "           [30.7159, 35.7802, 35.9490,  ..., 12.7607,  7.7941,  7.3397],\n",
       "           [33.9476, 33.2658, 38.6541,  ..., 12.6016,  9.6292,  6.8093]]]),\n",
       "  tensor([[[52.0879, 47.2241, 51.6007,  ..., 56.9871, 68.9948, 72.8828],\n",
       "           [43.9195, 57.1403, 51.1749,  ..., 56.5617, 59.6642, 61.3878],\n",
       "           [38.1374, 47.4100, 57.2868,  ..., 54.9778, 65.0723, 64.1271],\n",
       "           ...,\n",
       "           [35.9042, 48.8552, 57.4748,  ..., 11.7438,  8.8843, 12.1989],\n",
       "           [30.3810, 46.5353, 53.1783,  ..., 12.2148,  9.9904,  9.0581],\n",
       "           [32.9801, 40.3633, 53.0939,  ..., 10.1786, 12.3160,  8.1667]]])))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdataset[0], dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brazilian-currency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Dataset \"val2017\" loaded: 5000 samples, 5000 batches\n"
     ]
    }
   ],
   "source": [
    "dataset = load_predict_dataset(args.data_dir, None, args.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "identified-europe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-55a9d71005c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object does not support indexing"
     ]
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-denmark",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
